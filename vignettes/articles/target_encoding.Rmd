---
title: "Target Encoding"
output: 
  rmarkdown::html_document:
    toc: true
    toc_title: "Content"
    source: false
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  eval = TRUE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

## Summary

[**Target encoding**](https://www.blasbenito.com/post/target-encoding/) maps categorical predictors to a statistic of a reference numeric variable across categories. 

This functionality, implemented in [target_encoding_lab()], is used in two different ways:

  - [cor_df()] applies it to compute pairwise correlations between numeric and categorical predictors, if any.
  - [collinear()] applies it optionally if the user requests it and the response is numeric to transform all categorical predictors to numeric and speed-up the multicollinearity analysis.


## Target Encoding

To explain how target encoding works, let's first create a little silly dataframe:

```{r}
df <- data.frame(
  num = 1:6,
  cat = c(rep("a", 3), rep("b", 3))
)

df
```

### Mean Target Encoding

To transform `cat` to numeric we can remap it to the average of `num` across each category in `cat`, as shown in the code below using the `dplyr` syntax.

```{r}
df <- df |> 
  dplyr::group_by(cat) |> 
  dplyr::mutate(cat_mean = mean(num)) |> 
  dplyr::ungroup()

df
```

This is equivalent to the "mean" encoding method implemented in `target_encoding_lab()`.

```{r}
library(collinear)

df <- collinear::target_encoding_lab(
  df = df,
  response = "num",
  predictors = "cat",
  methods = "mean",
  quiet = TRUE
)

df
```

```{r, echo = FALSE}
df$cat_mean <- NULL
df$cat__encoded_mean <- NULL
```

### Leave-One-Out Target Encoding

Another encoding method is the leave-one-out (`"loo"`), which computes the group mean while excluding the current observation. 

For each given case, it sums the numeric values in the same category, subtracts the current row's value, and divides by the count of observations in that category minus one. The code below replicates this behavior.

```{r}
df <- df |> 
  dplyr::group_by(cat) |> 
  dplyr::mutate(
    cat_loo = (sum(num) - num) / (dplyr::n() - 1)
    ) |> 
  dplyr::ungroup()

df
```

Notice how the encoded values now vary within each category. For category "a": rows get values based on the other two observations in "a", and the same happens with "b".

The same method can be applied in `target_encoding_lab()` when setting `method` to `"loo"`.

```{r}
df <- collinear::target_encoding_lab(
  df = df,
  response = "num",
  predictors = "cat",
  methods = "loo",
  quiet = TRUE
)

df
```

```{r, echo = FALSE}
df$cat_loo <- NULL
df$cat__encoded_loo <- NULL
```


### Rank Target Encoding

The rank method orders categories by their mean values and assigns them integer ranks. It is useful  to capture the ordinal relationship between categories without being sensitive to outliers or extreme values.

The `dplyr` version of this algorithm is a bit more verbose, but I hope it does the trick:

```{r}
df <- df |> 
  dplyr::group_by(cat) |> 
  dplyr::mutate(cat_mean = mean(num)) |> 
  dplyr::ungroup() |> 
  dplyr::arrange(cat_mean) |> 
  dplyr::group_by(cat) |> 
  dplyr::mutate(cat_rank = dplyr::cur_group_id()) |> 
  dplyr::ungroup()

df
```

The same method can be applied via `target_encoding_lab()` with `encoding_method = "rank".

```{r}
df <- collinear::target_encoding_lab(
  df = df,
  response = "num",
  predictors = "cat",
  methods = "rank",
  quiet = TRUE
)

df
```

## Target Encoding in Practice

### Computing Correlations with Mixed Variable Types

When computing pairwise correlations between numeric and categorical predictors, [cor_df()] automatically applies leave-one-out target encoding behind the scenes. 

```{r}
data(vi_smol)

x <- collinear::cor_df(
  df = collinear::vi_smol,
  predictors = c(
    "soil_temperature_mean", # numeric
    "koppen_zone"            # categorical
  ),
  quiet = TRUE
)

x
```

This is the same as applying `target_encoding_lab()` with method `"loo"` and then compute the pairwise correlation with `stats::cor()`.

```{r}
df <- collinear::target_encoding_lab(
  df = collinear::vi_smol,
  response = "soil_temperature_mean",
  predictor = "koppen_zone",
  encoding_method = "loo",
  overwrite = TRUE,
  quiet = TRUE
)

stats::cor(
  x = df$soil_temperature_mean,
  y = df$koppen_zone
)
```

### Speeding Up Multicollinearity Analysis

Enabling target encoding when working with numeric responses and categorical predictors in [collinear()] provides two key advantages: it speeds up computation considerably, and more importantly, it replaces Cramer's V associations between pairs of categorical variables with Pearson correlations between pairs of numeric variables, providing a more statistically sound multicollinearity assessment.

```{r}
# without target encoding
time_without <- system.time({
  result_without_encoding <- collinear::collinear(
    df = collinear::vi_smol,
    responses = "vi_numeric",
    predictors = collinear::vi_predictors_categorical,
    encoding_method = NULL,
    quiet = TRUE
  )
})

# with target encoding
time_with <- system.time({
  result_with_encoding <- collinear::collinear(
    df = collinear::vi_smol,
    responses = "vi_numeric",
    predictors = collinear::vi_predictors_categorical,
    encoding_method = "loo",
    quiet = TRUE
  )
})

data.frame(
  encoding = c("No", "Yes"),
  seconds = c(time_without["elapsed"], time_with["elapsed"])
)
```
The speed-up is considerable!

But that's not the only consequence of applying target encoding. Let's take a look at the variable selections on each run.

```{r}
result_without_encoding$vi_numeric$selection
```

```{r}
result_with_encoding$vi_numeric$selection
```
The selection resulting from the run with target encoding is a bit shorter. Why? Because without target encoding, pairwise associations between categorical predictors are computed with Cramer's V, which tends to underestimate association under high cardinality (number of categories).

Hence, when target encoding is applied, `collinear()` captures true multicollinearity and ensures a consistent filtering across all predictors, no matter their type.

## Important Considerations

**Overfitting Risk**: Mean encoding can leak information from the response into the predictor. The leave-one-out method mitigates this risk and is generally recommended for modeling workflows.

**Category Frequency**: Target encoding works best with categories that have sufficient observations. Categories with very few observations may produce unstable encoded values.

**When to Use Target Encoding**: Enable `encoding_method = "loo"` in `collinear()` when you have a numeric response and categorical predictors, and you want the most accurate multicollinearity assessment. The improved statistical soundness and computational speed make it the preferred approach for mixed data types.
